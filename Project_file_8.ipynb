{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mc0L2sToEVko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12e7c9f4-13c6-43e0-ac54-a9cc4871185e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Found 518 files belonging to 3 classes.\n",
            "Using 415 files for training.\n",
            "Found 518 files belonging to 3 classes.\n",
            "Using 103 files for validation.\n",
            "Data augmentation applied to the training dataset!\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/dataset/train'\n",
        "\n",
        "# Create datasets with a 20-80 train-validation split\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    dataset_path,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    dataset_path,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Normalize the pixel values\n",
        "def preprocess(image, label):\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, label\n",
        "\n",
        "# Define data augmentation pipeline\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomRotation(0.2),           # Random rotations up to 20%\n",
        "    tf.keras.layers.RandomWidth(0.2),              # Random horizontal shifts\n",
        "    tf.keras.layers.RandomHeight(0.2),             # Random vertical shifts\n",
        "    tf.keras.layers.RandomZoom(0.2),               # Random zooms\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),      # Random horizontal flips\n",
        "])\n",
        "\n",
        "# Preprocess training data with augmentation\n",
        "def preprocess_with_augmentation(image, label):\n",
        "    image = tf.cast(image, tf.float32) / 255.0  # Normalize pixel values\n",
        "    image = data_augmentation(image)  # Apply augmentation\n",
        "    return image, label\n",
        "\n",
        "# Apply preprocessing and augmentation to the training data\n",
        "train_dataset = train_dataset.map(preprocess_with_augmentation)\n",
        "\n",
        "# Apply preprocessing (without augmentation) to the validation data\n",
        "val_dataset = val_dataset.map(preprocess)\n",
        "\n",
        "# Optimize for performance\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_dataset = val_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# Print confirmation\n",
        "print(\"Data augmentation applied to the training dataset!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import (VGG19,DenseNet201, MobileNetV2,InceptionResNetV2)\n",
        "\n",
        "def build_and_train_model(base_model, train_dataset, val_dataset, num_classes=4, model_name=\"\"):\n",
        "    # Freeze the base model\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Build the model\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=val_dataset,\n",
        "        epochs=50,\n",
        "        callbacks=[\n",
        "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Evaluate\n",
        "    val_loss, val_accuracy = model.evaluate(val_dataset)\n",
        "    print(f\"{model_name} - Validation Accuracy: {val_accuracy:.2f}\")\n",
        "\n",
        "    return model, history\n"
      ],
      "metadata": {
        "id": "0Wxw4AvdEXKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import (VGG19, InceptionResNetV2, DenseNet201,MobileNetV2)\n",
        "\n",
        "# Define models to train\n",
        "pretrained_models = [\n",
        "    (\"DenseNet201\", DenseNet201(weights='imagenet', include_top=False, input_shape=(224, 224, 3))),\n",
        "    (\"MobileNetV2\", MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))),\n",
        "]\n",
        "\n",
        "# Storage for trained models and results\n",
        "trained_models = {}\n",
        "model_histories = {}\n",
        "results = []\n",
        "\n",
        "# Train each model\n",
        "for model_name, base_model in pretrained_models:\n",
        "    print(f\"Training {model_name}...\")\n",
        "    model, history = build_and_train_model(base_model, train_dataset, val_dataset, model_name=model_name)\n",
        "    trained_models[model_name] = model\n",
        "    model_histories[model_name] = history\n",
        "    val_loss, val_accuracy = model.evaluate(val_dataset)\n",
        "    results.append((model_name, val_accuracy))"
      ],
      "metadata": {
        "id": "r-WE3DCKEb7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune each model\n",
        "fine_tuned_results = []\n",
        "\n",
        "for model_name, base_model in pretrained_models:\n",
        "    print(f\"Fine-tuning {model_name}...\")\n",
        "    trained_model = trained_models[model_name]\n",
        "    base_model.trainable = True  # Unfreeze base model\n",
        "\n",
        "    # Compile with lower learning rate\n",
        "    trained_model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-5),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Fine-tune the model\n",
        "    fine_tune_history = trained_model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=val_dataset,\n",
        "        epochs=20,\n",
        "        callbacks=[\n",
        "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7),\n",
        "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Evaluate fine-tuned model\n",
        "    val_loss, val_accuracy = trained_model.evaluate(val_dataset)\n",
        "    fine_tuned_results.append((model_name, val_accuracy))\n",
        "    print(f\"{model_name} - Fine-tuned Validation Accuracy: {val_accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "g8ZhFOI0Ed-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Gather predictions from fine-tuned models\n",
        "predictions = []\n",
        "for model_name in trained_models:\n",
        "    print(f\"Predicting with {model_name}...\")\n",
        "    model = trained_models[model_name]\n",
        "    preds = model.predict(val_dataset)\n",
        "    predictions.append(preds)\n",
        "\n",
        "# Average predictions across models\n",
        "ensemble_preds = np.mean(predictions, axis=0)\n",
        "\n",
        "# Convert ensemble predictions to class labels\n",
        "final_preds = np.argmax(ensemble_preds, axis=1)\n",
        "\n",
        "# Evaluate ensemble performance\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_true = np.concatenate([y for x, y in val_dataset], axis=0)  # True labels\n",
        "ensemble_accuracy = accuracy_score(y_true, final_preds)\n",
        "print(f\"Ensemble Model Accuracy: {ensemble_accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "Ch_OnMKaEgbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications\n",
        "import (VGG19, InceptionResNetV2, DenseNet201, MobileNetV2,)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from itertools import cycle\n",
        "\n",
        "# Function to plot ROC curves\n",
        "def plot_roc_curve(models, val_dataset, n_classes=4):\n",
        "    model_roc_data = {}\n",
        "\n",
        "    # Iterate over each model\n",
        "    for model_name, model in models:\n",
        "        print(f\"Evaluating {model_name}...\")\n",
        "\n",
        "        # Get true labels and predictions\n",
        "        y_true = np.concatenate([y for _, y in val_dataset], axis=0)\n",
        "        y_pred_proba = model.predict(val_dataset)\n",
        "\n",
        "        # One-hot encode true labels\n",
        "        y_true_bin = label_binarize(y_true, classes=range(n_classes))\n",
        "\n",
        "        # Compute ROC curve and AUC\n",
        "        fpr, tpr, roc_auc = {}, {}, {}\n",
        "        for i in range(n_classes):\n",
        "            fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_proba[:, i])\n",
        "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "        # Micro-average ROC curve\n",
        "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_bin.ravel(), y_pred_proba.ravel())\n",
        "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "        # Store results for plotting\n",
        "        model_roc_data[model_name] = (fpr, tpr, roc_auc)\n",
        "\n",
        "    # Plot ROC curves for all models\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    colors = cycle([\"blue\", \"red\", \"green\", \"orange\", \"purple\", \"cyan\", \"magenta\", \"brown\", \"grey\", \"pink\"])\n",
        "    for model_name, color in zip(model_roc_data.keys(), colors):\n",
        "        fpr, tpr, roc_auc = model_roc_data[model_name]\n",
        "\n",
        "        # Plot micro-average\n",
        "        plt.plot(\n",
        "            fpr[\"micro\"], tpr[\"micro\"], color=color, linestyle=\"--\", lw=2,\n",
        "            label=f\"{model_name} (AUC = {roc_auc['micro']:.2f})\"\n",
        "        )\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], \"k--\", lw=2)  # Diagonal line\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel(\"False Positive Rate\", fontsize=14)\n",
        "    plt.ylabel(\"True Positive Rate\", fontsize=14)\n",
        "    plt.title(\"ROC Curve for Multiple Models\", fontsize=16)\n",
        "    plt.legend(loc=\"lower right\", fontsize=12)\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "# Example of training models\n",
        "models_to_train = [\n",
        "    (\"DenseNet201\", DenseNet201(weights='imagenet', include_top=False, input_shape=(224, 224, 3))),\n",
        "    (\"MobileNetV2\", MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))),\n",
        "]\n",
        "\n",
        "\n",
        "# Placeholder for trained models and histories\n",
        "trained_models = []\n",
        "model_histories = []\n",
        "\n",
        "for model_name, base_model in models_to_train:\n",
        "    print(f\"Training {model_name}...\")\n",
        "    model, history = build_and_train_model(base_model, train_dataset, val_dataset, model_name=model_name)\n",
        "    trained_models.append((model_name, model))\n",
        "    model_histories.append(history)\n",
        "\n",
        "# Plot Loss/Accuracy for all models\n",
        "plot_loss_accuracy_graphs(model_histories, [model_name for model_name, _ in models_to_train])\n",
        "\n",
        "# Plot ROC curve\n",
        "plot_roc_curve(trained_models, val_dataset, n_classes=4)\n"
      ],
      "metadata": {
        "id": "1KbJS6ywEiqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_loss_accuracy_graphs(models_history, model_names):\n",
        "    \"\"\"\n",
        "    Plots Loss and Accuracy for multiple models in one graph.\n",
        "\n",
        "    Arguments:\n",
        "    models_history : list of histories - training histories of the models.\n",
        "    model_names : list of model names - names for each model.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    # Subplot 1: Accuracy Graph\n",
        "    plt.subplot(1, 2, 1)\n",
        "    for history, name in zip(models_history, model_names):\n",
        "        plt.plot(history.history['accuracy'], label=f'{name} - Train')\n",
        "        plt.plot(history.history['val_accuracy'], label=f'{name} - Validation')\n",
        "    plt.title('Accuracy for Models')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Subplot 2: Loss Graph\n",
        "    plt.subplot(1, 2, 2)\n",
        "    for history, name in zip(models_history, model_names):\n",
        "        plt.plot(history.history['loss'], label=f'{name} - Train')\n",
        "        plt.plot(history.history['val_loss'], label=f'{name} - Validation')\n",
        "    plt.title('Loss for Models')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Assuming you have a list of trained models and their histories\n",
        "models_history = [ history_densenet201,\n",
        "                  history_mobilenetv2]\n",
        "model_names = [\"DenseNet201\",\n",
        "                \"MobileNetV2\"]\n",
        "\n",
        "# Call the function to plot loss and accuracy graphs\n",
        "plot_loss_accuracy_graphs(models_history, model_names)\n"
      ],
      "metadata": {
        "id": "iAzOp7JIEk9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc_curve_separate(models, val_dataset, n_classes=4):\n",
        "    \"\"\"\n",
        "    Plot separate ROC curves for each model.\n",
        "    \"\"\"\n",
        "    for model_name, model in models:\n",
        "        print(f\"Evaluating {model_name}...\")\n",
        "\n",
        "        # Get true labels and predictions\n",
        "        y_true = np.concatenate([y for _, y in val_dataset], axis=0)\n",
        "        y_pred_proba = model.predict(val_dataset)\n",
        "\n",
        "        # One-hot encode true labels\n",
        "        y_true_bin = label_binarize(y_true, classes=range(n_classes))\n",
        "\n",
        "        # Compute ROC curve and AUC\n",
        "        fpr, tpr, roc_auc = {}, {}, {}\n",
        "        for i in range(n_classes):\n",
        "            fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_proba[:, i])\n",
        "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "        # Micro-average ROC curve\n",
        "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_bin.ravel(), y_pred_proba.ravel())\n",
        "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "        # Plot ROC curve for the current model\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        colors = cycle([\"blue\", \"red\", \"green\", \"orange\"])\n",
        "\n",
        "        for i, color in zip(range(n_classes), colors):\n",
        "            plt.plot(\n",
        "                fpr[i], tpr[i], color=color, lw=2,\n",
        "                label=f\"Class {i} (AUC = {roc_auc[i]:.2f})\"\n",
        "            )\n",
        "\n",
        "        # Plot micro-average\n",
        "        plt.plot(\n",
        "            fpr[\"micro\"], tpr[\"micro\"], color=\"purple\", linestyle=\"--\", lw=2,\n",
        "            label=f\"Micro-average (AUC = {roc_auc['micro']:.2f})\"\n",
        "        )\n",
        "\n",
        "        plt.plot([0, 1], [0, 1], \"k--\", lw=2)  # Diagonal line\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel(\"False Positive Rate\", fontsize=14)\n",
        "        plt.ylabel(\"True Positive Rate\", fontsize=14)\n",
        "        plt.title(f\"ROC Curve for {model_name}\", fontsize=16)\n",
        "        plt.legend(loc=\"lower right\", fontsize=12)\n",
        "        plt.grid(alpha=0.3)\n",
        "        plt.show()\n",
        "\n",
        "# Plot ROC curve for each model separately\n",
        "plot_roc_curve_separate(trained_models, val_dataset, n_classes=4)\n"
      ],
      "metadata": {
        "id": "p9724svzEm5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_and_accuracy_separately(models_history, model_names):\n",
        "    \"\"\"\n",
        "    Plots separate Loss and Accuracy graphs for each model.\n",
        "\n",
        "    Arguments:\n",
        "    models_history : list of histories - training histories of the models.\n",
        "    model_names : list of model names - names for each model.\n",
        "    \"\"\"\n",
        "    for history, name in zip(models_history, model_names):\n",
        "        # Plot Accuracy\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "        plt.title(f'Accuracy for {name}')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend(loc='lower right')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "        # Plot Loss\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(history.history['loss'], label='Train Loss')\n",
        "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "        plt.title(f'Loss for {name}')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend(loc='upper right')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "# Assuming you have a list of trained models and their histories\n",
        "models_history = [history_densenet201, history_mobilenetv2]\n",
        "model_names =  [\"DenseNet201\", \"MobileNetV2\"]\n",
        "\n",
        "# Call the function to plot separate graphs\n",
        "plot_loss_and_accuracy_separately(models_history, model_names)\n"
      ],
      "metadata": {
        "id": "MyXbWwGrEouk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}