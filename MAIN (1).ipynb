{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3SeZXRB_G35",
        "outputId": "6d13660c-81b8-44e1-947d-5f696ac5222b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Found 633 files belonging to 4 classes.\n",
            "Using 507 files for training.\n",
            "Found 633 files belonging to 4 classes.\n",
            "Using 126 files for validation.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/dataset/train'\n",
        "\n",
        "# Create datasets with a 20-80 train-validation split\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    dataset_path,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    dataset_path,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Normalize the pixel values\n",
        "def preprocess(image, label):\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, label\n",
        "\n",
        "train_dataset = train_dataset.map(preprocess)\n",
        "val_dataset = val_dataset.map(preprocess)\n",
        "\n",
        "# Optimize for performance\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_dataset = val_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import (VGG19, ResNet152V2, InceptionResNetV2,\n",
        "                                           DenseNet201, Xception, MobileNetV2,\n",
        "                                           NASNetMobile, EfficientNetB7)\n",
        "\n",
        "def build_and_train_model(base_model, train_dataset, val_dataset, num_classes=4, model_name=\"\"):\n",
        "    # Freeze the base model\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Build the model\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=val_dataset,\n",
        "        epochs=15,\n",
        "        callbacks=[\n",
        "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Evaluate\n",
        "    val_loss, val_accuracy = model.evaluate(val_dataset)\n",
        "    print(f\"{model_name} - Validation Accuracy: {val_accuracy:.2f}\")\n",
        "\n",
        "    return model, history\n"
      ],
      "metadata": {
        "id": "pgo8VFcIDiKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from tensorflow.keras.applications import (\n",
        "    VGG19, ResNet152V2, InceptionResNetV2, DenseNet201,\n",
        "    Xception, MobileNetV2, NASNetMobile, EfficientNetB7\n",
        ")\n",
        "\n",
        "# Define models to train\n",
        "pretrained_models = [\n",
        "    (\"VGG19\", VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))),\n",
        "    (\"ResNet152V2\", ResNet152V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))),\n",
        "    (\"InceptionResNetV2\", InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))),\n",
        "    (\"DenseNet201\", DenseNet201(weights='imagenet', include_top=False, input_shape=(224, 224, 3))),\n",
        "    (\"Xception\", Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))),\n",
        "    (\"MobileNetV2\", MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))),\n",
        "    (\"NASNetMobile\", NASNetMobile(weights='imagenet', include_top=False, input_shape=(224, 224, 3))),\n",
        "    (\"EfficientNetB7\", EfficientNetB7(weights='imagenet', include_top=False, input_shape=(224, 224, 3))),\n",
        "]\n",
        "\n",
        "# Storage for trained models and results\n",
        "trained_models = {}\n",
        "model_histories = {}\n",
        "results = []\n",
        "\n",
        "# Train each model\n",
        "for model_name, base_model in pretrained_models:\n",
        "    print(f\"Training {model_name}...\")\n",
        "    model, history = build_and_train_model(base_model, train_dataset, val_dataset, model_name=model_name)\n",
        "    trained_models[model_name] = model\n",
        "    model_histories[model_name] = history\n",
        "    val_loss, val_accuracy = model.evaluate(val_dataset)\n",
        "    results.append((model_name, val_accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tdqVxotD955",
        "outputId": "e9257101-7d5b-4006-a119-5826af3a899b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m80134624/80134624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m234545216/234545216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m219055592/219055592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m74836368/74836368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m83683744/83683744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-mobile-no-top.h5\n",
            "\u001b[1m19993432/19993432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n",
            "\u001b[1m258076736/258076736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 0us/step\n",
            "Training VGG19...\n",
            "Epoch 1/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m591s\u001b[0m 33s/step - accuracy: 0.2330 - loss: 1.6096 - val_accuracy: 0.3810 - val_loss: 1.3450\n",
            "Epoch 2/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m541s\u001b[0m 32s/step - accuracy: 0.3230 - loss: 1.3967 - val_accuracy: 0.4762 - val_loss: 1.2857\n",
            "Epoch 3/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 35s/step - accuracy: 0.3592 - loss: 1.3432 - val_accuracy: 0.3016 - val_loss: 1.3200\n",
            "Epoch 4/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m520s\u001b[0m 32s/step - accuracy: 0.4282 - loss: 1.2718 - val_accuracy: 0.5159 - val_loss: 1.2063\n",
            "Epoch 5/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m604s\u001b[0m 35s/step - accuracy: 0.5067 - loss: 1.1957 - val_accuracy: 0.5873 - val_loss: 1.1738\n",
            "Epoch 6/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m518s\u001b[0m 32s/step - accuracy: 0.5331 - loss: 1.1376 - val_accuracy: 0.5476 - val_loss: 1.1512\n",
            "Epoch 7/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 32s/step - accuracy: 0.4810 - loss: 1.1683 - val_accuracy: 0.5476 - val_loss: 1.1301\n",
            "Epoch 8/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 35s/step - accuracy: 0.5376 - loss: 1.0872 - val_accuracy: 0.5556 - val_loss: 1.1052\n",
            "Epoch 9/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 32s/step - accuracy: 0.5573 - loss: 1.0639 - val_accuracy: 0.5794 - val_loss: 1.0761\n",
            "Epoch 10/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 32s/step - accuracy: 0.5439 - loss: 1.0684 - val_accuracy: 0.4841 - val_loss: 1.0898\n",
            "Epoch 11/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 32s/step - accuracy: 0.5469 - loss: 1.0588 - val_accuracy: 0.6032 - val_loss: 1.0478\n",
            "Epoch 12/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m509s\u001b[0m 32s/step - accuracy: 0.5949 - loss: 0.9805 - val_accuracy: 0.5238 - val_loss: 1.0581\n",
            "Epoch 13/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 32s/step - accuracy: 0.5803 - loss: 1.0029 - val_accuracy: 0.5556 - val_loss: 1.0536\n",
            "Epoch 14/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 32s/step - accuracy: 0.6166 - loss: 0.9787 - val_accuracy: 0.5794 - val_loss: 1.0148\n",
            "Epoch 15/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 32s/step - accuracy: 0.5969 - loss: 0.9530 - val_accuracy: 0.6032 - val_loss: 1.0075\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 25s/step - accuracy: 0.6059 - loss: 1.0011\n",
            "VGG19 - Validation Accuracy: 0.60\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 25s/step - accuracy: 0.6059 - loss: 1.0011\n",
            "Training ResNet152V2...\n",
            "Epoch 1/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 22s/step - accuracy: 0.3392 - loss: 1.8471 - val_accuracy: 0.4921 - val_loss: 1.1743\n",
            "Epoch 2/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 20s/step - accuracy: 0.5552 - loss: 1.0647 - val_accuracy: 0.4683 - val_loss: 1.1900\n",
            "Epoch 3/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 22s/step - accuracy: 0.6301 - loss: 0.9097 - val_accuracy: 0.4841 - val_loss: 1.1397\n",
            "Epoch 4/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 20s/step - accuracy: 0.7334 - loss: 0.7540 - val_accuracy: 0.5476 - val_loss: 1.1217\n",
            "Epoch 5/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 20s/step - accuracy: 0.7441 - loss: 0.6888 - val_accuracy: 0.5238 - val_loss: 1.1338\n",
            "Epoch 6/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 22s/step - accuracy: 0.7974 - loss: 0.5737 - val_accuracy: 0.5079 - val_loss: 1.1457\n",
            "Epoch 7/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 21s/step - accuracy: 0.7772 - loss: 0.5652 - val_accuracy: 0.5635 - val_loss: 1.1749\n",
            "Epoch 8/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 22s/step - accuracy: 0.8526 - loss: 0.4758 - val_accuracy: 0.5238 - val_loss: 1.1920\n",
            "Epoch 9/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 20s/step - accuracy: 0.8870 - loss: 0.3644 - val_accuracy: 0.5000 - val_loss: 1.2410\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 16s/step - accuracy: 0.5638 - loss: 1.0511\n",
            "ResNet152V2 - Validation Accuracy: 0.55\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 16s/step - accuracy: 0.5638 - loss: 1.0511\n",
            "Training InceptionResNetV2...\n",
            "Epoch 1/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 12s/step - accuracy: 0.3495 - loss: 2.1137 - val_accuracy: 0.2937 - val_loss: 1.5677\n",
            "Epoch 2/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 12s/step - accuracy: 0.3854 - loss: 1.4742 - val_accuracy: 0.5556 - val_loss: 1.1245\n",
            "Epoch 3/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 11s/step - accuracy: 0.5044 - loss: 1.1281 - val_accuracy: 0.5794 - val_loss: 1.1042\n",
            "Epoch 4/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 12s/step - accuracy: 0.5420 - loss: 1.0486 - val_accuracy: 0.5556 - val_loss: 1.0984\n",
            "Epoch 5/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 12s/step - accuracy: 0.5352 - loss: 1.0886 - val_accuracy: 0.5397 - val_loss: 1.0632\n",
            "Epoch 6/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 12s/step - accuracy: 0.5570 - loss: 0.9960 - val_accuracy: 0.5397 - val_loss: 1.0937\n",
            "Epoch 7/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 11s/step - accuracy: 0.5843 - loss: 1.0089 - val_accuracy: 0.5952 - val_loss: 1.0395\n",
            "Epoch 8/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 12s/step - accuracy: 0.5963 - loss: 0.9673 - val_accuracy: 0.5873 - val_loss: 1.0635\n",
            "Epoch 9/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 12s/step - accuracy: 0.6257 - loss: 0.9217 - val_accuracy: 0.5794 - val_loss: 1.0028\n",
            "Epoch 10/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 11s/step - accuracy: 0.5926 - loss: 0.9611 - val_accuracy: 0.5952 - val_loss: 1.0154\n",
            "Epoch 11/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 12s/step - accuracy: 0.6612 - loss: 0.9136 - val_accuracy: 0.5556 - val_loss: 1.0896\n",
            "Epoch 12/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 12s/step - accuracy: 0.5732 - loss: 0.9012 - val_accuracy: 0.5556 - val_loss: 1.0987\n",
            "Epoch 13/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 12s/step - accuracy: 0.6830 - loss: 0.8933 - val_accuracy: 0.5952 - val_loss: 1.0289\n",
            "Epoch 14/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 12s/step - accuracy: 0.6478 - loss: 0.8344 - val_accuracy: 0.6190 - val_loss: 1.0083\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 9s/step - accuracy: 0.6005 - loss: 0.9395\n",
            "InceptionResNetV2 - Validation Accuracy: 0.58\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 9s/step - accuracy: 0.6005 - loss: 0.9395\n",
            "Training DenseNet201...\n",
            "Epoch 1/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 13s/step - accuracy: 0.3132 - loss: 1.7946 - val_accuracy: 0.2222 - val_loss: 1.4263\n",
            "Epoch 2/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 12s/step - accuracy: 0.3940 - loss: 1.3431 - val_accuracy: 0.3492 - val_loss: 1.2761\n",
            "Epoch 3/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 12s/step - accuracy: 0.4886 - loss: 1.1095 - val_accuracy: 0.4683 - val_loss: 1.1969\n",
            "Epoch 4/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 12s/step - accuracy: 0.5672 - loss: 1.0239 - val_accuracy: 0.5317 - val_loss: 1.1140\n",
            "Epoch 5/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 12s/step - accuracy: 0.5840 - loss: 0.9428 - val_accuracy: 0.5635 - val_loss: 1.0434\n",
            "Epoch 6/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 12s/step - accuracy: 0.6763 - loss: 0.8686 - val_accuracy: 0.5714 - val_loss: 1.0667\n",
            "Epoch 7/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 12s/step - accuracy: 0.6571 - loss: 0.8828 - val_accuracy: 0.5714 - val_loss: 1.0342\n",
            "Epoch 8/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 12s/step - accuracy: 0.6812 - loss: 0.7915 - val_accuracy: 0.5556 - val_loss: 1.0117\n",
            "Epoch 9/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 12s/step - accuracy: 0.7241 - loss: 0.7180 - val_accuracy: 0.5556 - val_loss: 1.0055\n",
            "Epoch 10/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 12s/step - accuracy: 0.7255 - loss: 0.6848 - val_accuracy: 0.5397 - val_loss: 1.0103\n",
            "Epoch 11/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 11s/step - accuracy: 0.7424 - loss: 0.6484 - val_accuracy: 0.5635 - val_loss: 1.0425\n",
            "Epoch 12/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 12s/step - accuracy: 0.8041 - loss: 0.5549 - val_accuracy: 0.5556 - val_loss: 1.0275\n",
            "Epoch 13/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 12s/step - accuracy: 0.7633 - loss: 0.5675 - val_accuracy: 0.6111 - val_loss: 1.0404\n",
            "Epoch 14/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 12s/step - accuracy: 0.8065 - loss: 0.5401 - val_accuracy: 0.5952 - val_loss: 0.9877\n",
            "Epoch 15/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 12s/step - accuracy: 0.8466 - loss: 0.4503 - val_accuracy: 0.5952 - val_loss: 1.0226\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 9s/step - accuracy: 0.6037 - loss: 0.9789\n",
            "DenseNet201 - Validation Accuracy: 0.60\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 9s/step - accuracy: 0.6037 - loss: 0.9789\n",
            "Training Xception...\n",
            "Epoch 1/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 10s/step - accuracy: 0.3111 - loss: 1.4877 - val_accuracy: 0.4444 - val_loss: 1.1741\n",
            "Epoch 2/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 10s/step - accuracy: 0.5052 - loss: 1.1529 - val_accuracy: 0.4683 - val_loss: 1.1163\n",
            "Epoch 3/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 10s/step - accuracy: 0.6038 - loss: 0.9795 - val_accuracy: 0.5476 - val_loss: 1.0620\n",
            "Epoch 4/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 11s/step - accuracy: 0.6133 - loss: 0.8793 - val_accuracy: 0.5317 - val_loss: 1.0615\n",
            "Epoch 5/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 10s/step - accuracy: 0.6890 - loss: 0.8145 - val_accuracy: 0.4762 - val_loss: 1.1183\n",
            "Epoch 6/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 10s/step - accuracy: 0.6270 - loss: 0.8349 - val_accuracy: 0.5079 - val_loss: 1.0619\n",
            "Epoch 7/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 10s/step - accuracy: 0.7262 - loss: 0.7558 - val_accuracy: 0.5556 - val_loss: 1.0455\n",
            "Epoch 8/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 11s/step - accuracy: 0.7143 - loss: 0.7220 - val_accuracy: 0.5714 - val_loss: 1.0195\n",
            "Epoch 9/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 11s/step - accuracy: 0.7551 - loss: 0.6404 - val_accuracy: 0.5556 - val_loss: 1.0268\n",
            "Epoch 10/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 10s/step - accuracy: 0.7772 - loss: 0.6183 - val_accuracy: 0.5556 - val_loss: 1.0278\n",
            "Epoch 11/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 10s/step - accuracy: 0.7627 - loss: 0.6010 - val_accuracy: 0.5476 - val_loss: 1.0092\n",
            "Epoch 12/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 10s/step - accuracy: 0.7605 - loss: 0.6057 - val_accuracy: 0.5556 - val_loss: 1.0586\n",
            "Epoch 13/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 11s/step - accuracy: 0.8202 - loss: 0.5014 - val_accuracy: 0.5794 - val_loss: 1.0728\n",
            "Epoch 14/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 10s/step - accuracy: 0.8155 - loss: 0.4843 - val_accuracy: 0.5397 - val_loss: 1.0765\n",
            "Epoch 15/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 10s/step - accuracy: 0.8506 - loss: 0.4274 - val_accuracy: 0.5397 - val_loss: 1.0585\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8s/step - accuracy: 0.5690 - loss: 0.9642\n",
            "Xception - Validation Accuracy: 0.55\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8s/step - accuracy: 0.5690 - loss: 0.9642\n",
            "Training MobileNetV2...\n",
            "Epoch 1/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.3365 - loss: 1.7562 - val_accuracy: 0.5556 - val_loss: 1.0863\n",
            "Epoch 2/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.5739 - loss: 1.0263 - val_accuracy: 0.5556 - val_loss: 1.0144\n",
            "Epoch 3/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.6510 - loss: 0.8687 - val_accuracy: 0.5397 - val_loss: 1.0091\n",
            "Epoch 4/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - accuracy: 0.7237 - loss: 0.7724 - val_accuracy: 0.6270 - val_loss: 0.9380\n",
            "Epoch 5/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - accuracy: 0.7695 - loss: 0.6287 - val_accuracy: 0.5635 - val_loss: 0.9316\n",
            "Epoch 6/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2s/step - accuracy: 0.7351 - loss: 0.6912 - val_accuracy: 0.5873 - val_loss: 0.9105\n",
            "Epoch 7/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.8222 - loss: 0.5108 - val_accuracy: 0.6349 - val_loss: 0.9022\n",
            "Epoch 8/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - accuracy: 0.8587 - loss: 0.4322 - val_accuracy: 0.6111 - val_loss: 0.8950\n",
            "Epoch 9/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.8445 - loss: 0.4281 - val_accuracy: 0.6508 - val_loss: 0.8994\n",
            "Epoch 10/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2s/step - accuracy: 0.8653 - loss: 0.3849 - val_accuracy: 0.6429 - val_loss: 0.8763\n",
            "Epoch 11/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - accuracy: 0.8943 - loss: 0.3530 - val_accuracy: 0.6667 - val_loss: 0.8664\n",
            "Epoch 12/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.9058 - loss: 0.2819 - val_accuracy: 0.6587 - val_loss: 0.8733\n",
            "Epoch 13/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2s/step - accuracy: 0.9212 - loss: 0.2597 - val_accuracy: 0.6508 - val_loss: 0.9333\n",
            "Epoch 14/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - accuracy: 0.9207 - loss: 0.2591 - val_accuracy: 0.6190 - val_loss: 0.9667\n",
            "Epoch 15/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.9371 - loss: 0.2303 - val_accuracy: 0.6349 - val_loss: 0.9417\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.6677 - loss: 0.8691\n",
            "MobileNetV2 - Validation Accuracy: 0.67\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.6677 - loss: 0.8691\n",
            "Training NASNetMobile...\n",
            "Epoch 1/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 4s/step - accuracy: 0.3207 - loss: 1.5129 - val_accuracy: 0.4603 - val_loss: 1.2586\n",
            "Epoch 2/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3s/step - accuracy: 0.4077 - loss: 1.3557 - val_accuracy: 0.4286 - val_loss: 1.1661\n",
            "Epoch 3/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.4932 - loss: 1.1536 - val_accuracy: 0.4365 - val_loss: 1.2142\n",
            "Epoch 4/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 4s/step - accuracy: 0.5461 - loss: 1.0409 - val_accuracy: 0.5317 - val_loss: 1.1326\n",
            "Epoch 5/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 4s/step - accuracy: 0.6194 - loss: 0.9724 - val_accuracy: 0.5317 - val_loss: 1.1067\n",
            "Epoch 6/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.5903 - loss: 0.9448 - val_accuracy: 0.5000 - val_loss: 1.1027\n",
            "Epoch 7/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 4s/step - accuracy: 0.6284 - loss: 0.8841 - val_accuracy: 0.5079 - val_loss: 1.1223\n",
            "Epoch 8/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 3s/step - accuracy: 0.6375 - loss: 0.8661 - val_accuracy: 0.5079 - val_loss: 1.1077\n",
            "Epoch 9/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 4s/step - accuracy: 0.7102 - loss: 0.7925 - val_accuracy: 0.5159 - val_loss: 1.1012\n",
            "Epoch 10/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3s/step - accuracy: 0.6669 - loss: 0.8018 - val_accuracy: 0.5476 - val_loss: 1.1018\n",
            "Epoch 11/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 4s/step - accuracy: 0.7074 - loss: 0.7472 - val_accuracy: 0.5397 - val_loss: 1.0968\n",
            "Epoch 12/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 3s/step - accuracy: 0.6999 - loss: 0.7396 - val_accuracy: 0.5476 - val_loss: 1.0951\n",
            "Epoch 13/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 4s/step - accuracy: 0.7268 - loss: 0.7185 - val_accuracy: 0.5238 - val_loss: 1.1211\n",
            "Epoch 14/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 4s/step - accuracy: 0.7251 - loss: 0.6783 - val_accuracy: 0.5159 - val_loss: 1.1903\n",
            "Epoch 15/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 4s/step - accuracy: 0.7495 - loss: 0.6550 - val_accuracy: 0.5556 - val_loss: 1.1565\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.5565 - loss: 1.0680\n",
            "NASNetMobile - Validation Accuracy: 0.55\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3s/step - accuracy: 0.5565 - loss: 1.0680\n",
            "Training EfficientNetB7...\n",
            "Epoch 1/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 25s/step - accuracy: 0.2267 - loss: 1.5721 - val_accuracy: 0.2063 - val_loss: 1.4137\n",
            "Epoch 2/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 24s/step - accuracy: 0.2802 - loss: 1.4373 - val_accuracy: 0.2460 - val_loss: 1.3851\n",
            "Epoch 3/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 25s/step - accuracy: 0.2276 - loss: 1.4170 - val_accuracy: 0.2063 - val_loss: 1.3948\n",
            "Epoch 4/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 25s/step - accuracy: 0.2246 - loss: 1.4041 - val_accuracy: 0.2460 - val_loss: 1.3847\n",
            "Epoch 5/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 24s/step - accuracy: 0.2417 - loss: 1.3935 - val_accuracy: 0.2063 - val_loss: 1.3901\n",
            "Epoch 6/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 23s/step - accuracy: 0.2819 - loss: 1.3939 - val_accuracy: 0.2063 - val_loss: 1.3969\n",
            "Epoch 7/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m399s\u001b[0m 25s/step - accuracy: 0.2971 - loss: 1.3909 - val_accuracy: 0.2063 - val_loss: 1.3873\n",
            "Epoch 8/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 24s/step - accuracy: 0.2524 - loss: 1.3861 - val_accuracy: 0.2063 - val_loss: 1.3875\n",
            "Epoch 9/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 25s/step - accuracy: 0.2684 - loss: 1.3870 - val_accuracy: 0.2063 - val_loss: 1.3941\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 19s/step - accuracy: 0.2547 - loss: 1.3837\n",
            "EfficientNetB7 - Validation Accuracy: 0.25\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 18s/step - accuracy: 0.2547 - loss: 1.3837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune each model\n",
        "fine_tuned_results = []\n",
        "\n",
        "for model_name, base_model in pretrained_models:\n",
        "    print(f\"Fine-tuning {model_name}...\")\n",
        "    trained_model = trained_models[model_name]\n",
        "    base_model.trainable = True  # Unfreeze base model\n",
        "\n",
        "    # Compile with lower learning rate\n",
        "    trained_model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-5),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Fine-tune the model\n",
        "    fine_tune_history = trained_model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=val_dataset,\n",
        "        epochs=20,\n",
        "        callbacks=[\n",
        "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7),\n",
        "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Evaluate fine-tuned model\n",
        "    val_loss, val_accuracy = trained_model.evaluate(val_dataset)\n",
        "    fine_tuned_results.append((model_name, val_accuracy))\n",
        "    print(f\"{model_name} - Fine-tuned Validation Accuracy: {val_accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRJK6rpUEUUw",
        "outputId": "bbd9108d-dc3c-43c6-fe17-6af1af876555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning VGG19...\n",
            "Epoch 1/60\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1607s\u001b[0m 100s/step - accuracy: 0.5556 - loss: 1.0237 - val_accuracy: 0.6190 - val_loss: 0.9316 - learning_rate: 1.0000e-05\n",
            "Epoch 2/60\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1534s\u001b[0m 96s/step - accuracy: 0.6799 - loss: 0.7965 - val_accuracy: 0.6429 - val_loss: 0.8533 - learning_rate: 1.0000e-05\n",
            "Epoch 3/60\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1574s\u001b[0m 96s/step - accuracy: 0.7610 - loss: 0.6400 - val_accuracy: 0.6190 - val_loss: 0.8110 - learning_rate: 1.0000e-05\n",
            "Epoch 4/60\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1538s\u001b[0m 97s/step - accuracy: 0.8203 - loss: 0.4663 - val_accuracy: 0.6270 - val_loss: 0.8617 - learning_rate: 1.0000e-05\n",
            "Epoch 5/60\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1547s\u001b[0m 97s/step - accuracy: 0.7958 - loss: 0.4542 - val_accuracy: 0.6587 - val_loss: 0.8405 - learning_rate: 1.0000e-05\n",
            "Epoch 6/60\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1569s\u001b[0m 99s/step - accuracy: 0.8692 - loss: 0.3711 - val_accuracy: 0.6905 - val_loss: 0.8174 - learning_rate: 1.0000e-05\n",
            "Epoch 7/60\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1540s\u001b[0m 97s/step - accuracy: 0.9261 - loss: 0.2839 - val_accuracy: 0.6667 - val_loss: 0.7889 - learning_rate: 2.0000e-06\n",
            "Epoch 8/60\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1576s\u001b[0m 96s/step - accuracy: 0.9341 - loss: 0.2667 - val_accuracy: 0.6587 - val_loss: 0.8045 - learning_rate: 2.0000e-06\n",
            "Epoch 9/60\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1525s\u001b[0m 96s/step - accuracy: 0.9355 - loss: 0.2211 - val_accuracy: 0.6825 - val_loss: 0.8097 - learning_rate: 2.0000e-06\n",
            "Epoch 10/60\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1531s\u001b[0m 96s/step - accuracy: 0.9474 - loss: 0.2009 - val_accuracy: 0.6825 - val_loss: 0.8270 - learning_rate: 2.0000e-06\n",
            "Epoch 11/60\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1532s\u001b[0m 96s/step - accuracy: 0.9413 - loss: 0.1992 - val_accuracy: 0.6825 - val_loss: 0.8259 - learning_rate: 4.0000e-07\n",
            "Epoch 12/60\n",
            "\u001b[1m 5/16\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m16:26\u001b[0m 90s/step - accuracy: 0.9235 - loss: 0.2495"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuned_results = []\n",
        "\n",
        "for model_name, base_model in pretrained_models:\n",
        "    print(f\"Fine-tuning {model_name}...\")\n",
        "    trained_model = trained_models[model_name]\n",
        "    base_model.trainable = True  # Unfreeze base model\n",
        "\n",
        "    # Compile with lower learning rate\n",
        "    trained_model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-5),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Fine-tune the model\n",
        "    fine_tune_history = trained_model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=val_dataset,\n",
        "        epochs=20,\n",
        "        callbacks=[\n",
        "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7),\n",
        "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Evaluate fine-tuned model\n",
        "    val_loss, val_accuracy = trained_model.evaluate(val_dataset)\n",
        "    fine_tuned_results.append((model_name, val_accuracy))\n",
        "    print(f\"{model_name} - Fine-tuned Validation Accuracy: {val_accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "JTHTiYZ7ohp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Gather predictions from fine-tuned models\n",
        "predictions = []\n",
        "for model_name in trained_models:\n",
        "    print(f\"Predicting with {model_name}...\")\n",
        "    model = trained_models[model_name]\n",
        "    preds = model.predict(val_dataset)\n",
        "    predictions.append(preds)\n",
        "\n",
        "# Average predictions across models\n",
        "ensemble_preds = np.mean(predictions, axis=0)\n",
        "\n",
        "# Convert ensemble predictions to class labels\n",
        "final_preds = np.argmax(ensemble_preds, axis=1)\n",
        "\n",
        "# Evaluate ensemble performance\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_true = np.concatenate([y for x, y in val_dataset], axis=0)  # True labels\n",
        "ensemble_accuracy = accuracy_score(y_true, final_preds)\n",
        "print(f\"Ensemble Model Accuracy: {ensemble_accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "T769lIiEEj7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications\n",
        "import (VGG19, ResNet152V2, InceptionResNetV2, DenseNet201,Xception, MobileNetV2, NASNetMobile, EfficientNetB7)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from itertools import cycle\n",
        "\n",
        "# Function to plot ROC curves\n",
        "def plot_roc_curve(models, val_dataset, n_classes=4):\n",
        "    model_roc_data = {}\n",
        "\n",
        "    # Iterate over each model\n",
        "    for model_name, model in models:\n",
        "        print(f\"Evaluating {model_name}...\")\n",
        "\n",
        "        # Get true labels and predictions\n",
        "        y_true = np.concatenate([y for _, y in val_dataset], axis=0)\n",
        "        y_pred_proba = model.predict(val_dataset)\n",
        "\n",
        "        # One-hot encode true labels\n",
        "        y_true_bin = label_binarize(y_true, classes=range(n_classes))\n",
        "\n",
        "        # Compute ROC curve and AUC\n",
        "        fpr, tpr, roc_auc = {}, {}, {}\n",
        "        for i in range(n_classes):\n",
        "            fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_proba[:, i])\n",
        "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "        # Micro-average ROC curve\n",
        "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_bin.ravel(), y_pred_proba.ravel())\n",
        "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "        # Store results for plotting\n",
        "        model_roc_data[model_name] = (fpr, tpr, roc_auc)\n",
        "\n",
        "    # Plot ROC curves for all models\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    colors = cycle([\"blue\", \"red\", \"green\", \"orange\", \"purple\", \"cyan\", \"magenta\", \"brown\", \"grey\", \"pink\"])\n",
        "    for model_name, color in zip(model_roc_data.keys(), colors):\n",
        "        fpr, tpr, roc_auc = model_roc_data[model_name]\n",
        "\n",
        "        # Plot micro-average\n",
        "        plt.plot(\n",
        "            fpr[\"micro\"], tpr[\"micro\"], color=color, linestyle=\"--\", lw=2,\n",
        "            label=f\"{model_name} (AUC = {roc_auc['micro']:.2f})\"\n",
        "        )\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], \"k--\", lw=2)  # Diagonal line\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel(\"False Positive Rate\", fontsize=14)\n",
        "    plt.ylabel(\"True Positive Rate\", fontsize=14)\n",
        "    plt.title(\"ROC Curve for Multiple Models\", fontsize=16)\n",
        "    plt.legend(loc=\"lower right\", fontsize=12)\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "# Example of training models\n",
        "models_to_train = [\n",
        "    (\"VGG19\", VGG19(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))),\n",
        "    (\"ResNet152V2\", ResNet152V2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))),\n",
        "    # Add other models here...\n",
        "]\n",
        "\n",
        "# Placeholder for trained models and histories\n",
        "trained_models = []\n",
        "model_histories = []\n",
        "\n",
        "for model_name, base_model in models_to_train:\n",
        "    print(f\"Training {model_name}...\")\n",
        "    model, history = build_and_train_model(base_model, train_dataset, val_dataset, model_name=model_name)\n",
        "    trained_models.append((model_name, model))\n",
        "    model_histories.append(history)\n",
        "\n",
        "# Plot Loss/Accuracy for all models\n",
        "plot_loss_accuracy_graphs(model_histories, [model_name for model_name, _ in models_to_train])\n",
        "\n",
        "# Plot ROC curve\n",
        "plot_roc_curve(trained_models, val_dataset, n_classes=4)\n"
      ],
      "metadata": {
        "id": "AXF30oGx1pzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_loss_accuracy_graphs(models_history, model_names):\n",
        "    \"\"\"\n",
        "    Plots Loss and Accuracy for multiple models in one graph.\n",
        "\n",
        "    Arguments:\n",
        "    models_history : list of histories - training histories of the models.\n",
        "    model_names : list of model names - names for each model.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    # Subplot 1: Accuracy Graph\n",
        "    plt.subplot(1, 2, 1)\n",
        "    for history, name in zip(models_history, model_names):\n",
        "        plt.plot(history.history['accuracy'], label=f'{name} - Train')\n",
        "        plt.plot(history.history['val_accuracy'], label=f'{name} - Validation')\n",
        "    plt.title('Accuracy for Models')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Subplot 2: Loss Graph\n",
        "    plt.subplot(1, 2, 2)\n",
        "    for history, name in zip(models_history, model_names):\n",
        "        plt.plot(history.history['loss'], label=f'{name} - Train')\n",
        "        plt.plot(history.history['val_loss'], label=f'{name} - Validation')\n",
        "    plt.title('Loss for Models')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Assuming you have a list of trained models and their histories\n",
        "models_history = [history_vgg19, history_resnet152v2, history_inceptionresnetv2, history_densenet201,\n",
        "                  history_xception, history_mobilenetv2, history_nasnetmobile, history_efficientnetb7]\n",
        "model_names = [\"VGG19\", \"ResNet152V2\", \"InceptionResNetV2\", \"DenseNet201\",\n",
        "               \"Xception\", \"MobileNetV2\", \"NASNetMobile\", \"EfficientNetB7\"]\n",
        "\n",
        "# Call the function to plot loss and accuracy graphs\n",
        "plot_loss_accuracy_graphs(models_history, model_names)\n"
      ],
      "metadata": {
        "id": "IbrYaaR94Fgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4pmV0xzL4ICv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}